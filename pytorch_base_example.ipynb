{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "PYTORCH_DEVICE = torch.device(\"cpu\") # \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "print(PYTORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape (569, 30)\n",
      "Y_shape (569,)\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_datset = sklearn.datasets.load_breast_cancer()\n",
    "\n",
    "X = breast_cancer_datset['data']\n",
    "Y = breast_cancer_datset['target']\n",
    "\n",
    "print(\"X_shape\", X.shape)\n",
    "print(\"Y_shape\", Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.3, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "train_dataset = SimpleDataset(X_train, Y_train)\n",
    "test_dataset = SimpleDataset(X_test, Y_test)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_dataloader_wrapper(dataloader):\n",
    "    while True:\n",
    "        for batch in dataloader:\n",
    "            yield batch\n",
    "            \n",
    "infinite_train_dataloader = infinite_dataloader_wrapper(train_dataloader)\n",
    "infinite_test_dataloader = infinite_dataloader_wrapper(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, input_features_count, num_classes):\n",
    "        super(SimpleClassificationModel, self).__init__()\n",
    "        self.some_sequential_block = nn.Sequential(\n",
    "            nn.Linear(input_features_count, input_features_count),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.final_fc = nn.Linear(input_features_count, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.some_sequential_block(x)\n",
    "        x = self.final_fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleClassificationModel(X.shape[1], max(Y.tolist()) + 1).to(PYTORCH_DEVICE)\n",
    "loss_function = torch.nn.CrossEntropyLoss().to(PYTORCH_DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f24495849184a43a4553032c793075a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train\n",
      "loss 0.1141901\n",
      "accuracy 0.96875\n",
      "0 test\n",
      "loss 0.038228974\n",
      "accuracy 0.984375\n",
      "1000 train\n",
      "loss 0.11041064\n",
      "accuracy 0.96875\n",
      "1000 test\n",
      "loss 0.07006152\n",
      "accuracy 0.9767441860465116\n",
      "2000 train\n",
      "loss 0.055502225\n",
      "accuracy 0.96875\n",
      "2000 test\n",
      "loss 0.16307618\n",
      "accuracy 0.953125\n",
      "3000 train\n",
      "loss 0.043022852\n",
      "accuracy 0.96875\n",
      "3000 test\n",
      "loss 0.028703675\n",
      "accuracy 1.0\n",
      "4000 train\n",
      "loss 0.0076737422\n",
      "accuracy 1.0\n",
      "4000 test\n",
      "loss 0.28652117\n",
      "accuracy 0.8837209302325582\n",
      "5000 train\n",
      "loss 0.011009355\n",
      "accuracy 1.0\n",
      "5000 test\n",
      "loss 0.12113373\n",
      "accuracy 0.953125\n",
      "6000 train\n",
      "loss 0.048908528\n",
      "accuracy 0.984375\n",
      "6000 test\n",
      "loss 0.27344567\n",
      "accuracy 0.9375\n",
      "7000 train\n",
      "loss 0.05113535\n",
      "accuracy 0.96875\n",
      "7000 test\n",
      "loss 0.098095074\n",
      "accuracy 0.9534883720930233\n",
      "8000 train\n",
      "loss 0.05593279\n",
      "accuracy 0.96875\n",
      "8000 test\n",
      "loss 0.07460085\n",
      "accuracy 0.953125\n",
      "9000 train\n",
      "loss 0.014173485\n",
      "accuracy 1.0\n",
      "9000 test\n",
      "loss 0.13026385\n",
      "accuracy 0.953125\n"
     ]
    }
   ],
   "source": [
    "def process_batch(generator, is_train, iteration):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    x_batch, y_batch = next(generator)\n",
    "    x_batch = x_batch.to(PYTORCH_DEVICE)\n",
    "    y_batch = y_batch.to(PYTORCH_DEVICE)\n",
    "    \n",
    "    \n",
    "    if is_train:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    y_predicted = model(x_batch)\n",
    "    assert not torch.any(torch.isnan(y_predicted))\n",
    "    loss = loss_function(y_predicted, y_batch)\n",
    "\n",
    "    if is_train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_or_test = \"train\" if is_train else \"test\"\n",
    "\n",
    "    y_batch_numpy = y_batch.cpu().detach().numpy()\n",
    "    y_predicted_class_numpy = y_predicted.cpu().detach().numpy().argmax(axis=1)\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "        # better way here is to calculate loss every time and push it to something like tensorboard\n",
    "        print(iteration, train_or_test)\n",
    "        print(\"loss\", loss.cpu().detach().numpy())\n",
    "        print(\"accuracy\", sklearn.metrics.accuracy_score(y_batch_numpy, y_predicted_class_numpy))\n",
    "\n",
    "\n",
    "for iteration in tqdm(range(10_000)):\n",
    "    process_batch(infinite_train_dataloader, True, iteration)\n",
    "    with torch.no_grad():\n",
    "        process_batch(infinite_test_dataloader, False, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54297c32b2f47eeb888113379a4ed79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train\n",
      "loss 0.028271738\n",
      "accuracy 1.0\n",
      "0 test\n",
      "loss 0.13713504\n",
      "accuracy 0.9534883720930233\n",
      "1000 train\n",
      "loss 0.016699992\n",
      "accuracy 1.0\n",
      "1000 test\n",
      "loss 0.03694469\n",
      "accuracy 0.984375\n",
      "2000 train\n",
      "loss 0.0047024027\n",
      "accuracy 1.0\n",
      "2000 test\n",
      "loss 0.13072795\n",
      "accuracy 0.96875\n",
      "3000 train\n",
      "loss 0.05325662\n",
      "accuracy 0.96875\n",
      "3000 test\n",
      "loss 0.20876445\n",
      "accuracy 0.9302325581395349\n",
      "4000 train\n",
      "loss 0.007911827\n",
      "accuracy 1.0\n",
      "4000 test\n",
      "loss 0.3298788\n",
      "accuracy 0.9375\n",
      "5000 train\n",
      "loss 0.024022082\n",
      "accuracy 0.984375\n",
      "5000 test\n",
      "loss 0.04369533\n",
      "accuracy 0.984375\n",
      "6000 train\n",
      "loss 0.01381294\n",
      "accuracy 0.984375\n",
      "6000 test\n",
      "loss 0.1008489\n",
      "accuracy 0.9767441860465116\n",
      "7000 train\n",
      "loss 0.062712364\n",
      "accuracy 0.96875\n",
      "7000 test\n",
      "loss 0.25300378\n",
      "accuracy 0.953125\n",
      "8000 train\n",
      "loss 0.046902932\n",
      "accuracy 0.984375\n",
      "8000 test\n",
      "loss 0.13067846\n",
      "accuracy 0.96875\n",
      "9000 train\n",
      "loss 0.0071885777\n",
      "accuracy 1.0\n",
      "9000 test\n",
      "loss 0.57413906\n",
      "accuracy 0.9069767441860465\n"
     ]
    }
   ],
   "source": [
    "# hacking of last layer on neural network and train only him\n",
    "for param in model.parameters():\n",
    "    model.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(X.shape[1], 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(X.shape[1], 2),\n",
    ")\n",
    "\n",
    "for iteration in tqdm(range(10_000)):\n",
    "    process_batch(infinite_train_dataloader, True, iteration)\n",
    "    with torch.no_grad():\n",
    "        process_batch(infinite_test_dataloader, False, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus for image tasks. for getting dataset for images and transform it. you coud use such code\n",
    "# from torchvision import transforms as T\n",
    "\n",
    "# transform = T.Compose([\n",
    "#     T.transforms.ToTensor(), \n",
    "#     T.transforms.Normalize([0.4, 0.4, 0.4], [0.4, 0.4, 0.4])]\n",
    "\n",
    "#     # Augmentations,\n",
    "#     # https://pytorch.org/vision/main/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "    \n",
    "# )\n",
    "\n",
    "# dataset = ImageFolder(\"your/folder\", transform=transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
