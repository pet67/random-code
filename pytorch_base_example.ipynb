{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "PYTORCH_DEVICE = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
    "print(PYTORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape (569, 30)\n",
      "Y_shape (569,)\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_datset = sklearn.datasets.load_breast_cancer()\n",
    "\n",
    "X = breast_cancer_datset['data']\n",
    "Y = breast_cancer_datset['target']\n",
    "\n",
    "print(\"X_shape\", X.shape)\n",
    "print(\"Y_shape\", Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.3, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.LongTensor(Y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "train_dataset = SimpleDataset(X_train, Y_train)\n",
    "test_dataset = SimpleDataset(X_test, Y_test)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_dataloader_wrapper(dataloader):\n",
    "    while True:\n",
    "        for batch in dataloader:\n",
    "            yield batch\n",
    "            \n",
    "infinite_train_dataloader = infinite_dataloader_wrapper(train_dataloader)\n",
    "infinite_test_dataloader = infinite_dataloader_wrapper(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, input_features_count, num_classes):\n",
    "        super(SimpleClassificationModel, self).__init__()\n",
    "        self.some_sequential_block = nn.Sequential(\n",
    "            nn.Linear(input_features_count, input_features_count),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.final_fc = nn.Linear(input_features_count, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.some_sequential_block(x)\n",
    "        x = self.final_fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleClassificationModel(X.shape[1], max(Y.tolist()) + 1).to(PYTORCH_DEVICE)\n",
    "loss_function = torch.nn.CrossEntropyLoss().to(PYTORCH_DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297972bc1b884b0f8b0bfe5417ac214f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train\n",
      "loss 31.68948\n",
      "accuracy 0.34375\n",
      "0 test\n",
      "loss 27.595242\n",
      "accuracy 0.34375\n",
      "250 train\n",
      "loss 0.120098464\n",
      "accuracy 0.953125\n",
      "250 test\n",
      "loss 0.24515913\n",
      "accuracy 0.921875\n",
      "500 train\n",
      "loss 0.18063208\n",
      "accuracy 0.890625\n",
      "500 test\n",
      "loss 0.09391493\n",
      "accuracy 0.9534883720930233\n",
      "750 train\n",
      "loss 0.20087877\n",
      "accuracy 0.9375\n",
      "750 test\n",
      "loss 0.11801361\n",
      "accuracy 0.96875\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "USE_TENSORBOARD = False\n",
    "tensorboard_writer = SummaryWriter(comment=f\"_{str(model.__class__.__name__)}\") if USE_TENSORBOARD else None\n",
    "\n",
    "def process_batch_metrics(results, is_train, iteration):\n",
    "    train_or_test = \"train\" if is_train else \"test\"\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(results[\"y_numpy\"], results[\"y_predicted_class_numpy\"])\n",
    "    \n",
    "    if iteration is not None:\n",
    "        if tensorboard_writer:\n",
    "            tensorboard_writer.add_scalar(f'{train_or_test}/loss', results[\"loss_numpy\"], iteration)\n",
    "            tensorboard_writer.add_scalar(f'{train_or_test}/accuracy', accuracy, iteration)\n",
    "        else:\n",
    "            if iteration % 250 == 0:\n",
    "                print(iteration, train_or_test)\n",
    "                print(\"loss\", results[\"loss_numpy\"])\n",
    "                print(\"accuracy\", accuracy)\n",
    "    \n",
    "\n",
    "def process_batch(batch, is_train, iteration):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    x, y = batch\n",
    "    x = x.to(PYTORCH_DEVICE)\n",
    "    y = y.to(PYTORCH_DEVICE)\n",
    "\n",
    "    if is_train:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    y_predicted = model(x)\n",
    "    assert not torch.any(torch.isnan(y_predicted))\n",
    "    loss = loss_function(y_predicted, y)\n",
    "\n",
    "    if is_train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    results = {}\n",
    "    results[\"y_numpy\"] = y.cpu().detach().numpy()\n",
    "    results[\"y_predicted_numpy\"] = y_predicted.cpu().detach().numpy()\n",
    "    results[\"y_predicted_class_numpy\"] = results[\"y_predicted_numpy\"].argmax(axis=1)\n",
    "    results[\"loss_numpy\"] = loss.cpu().detach().numpy()\n",
    "    \n",
    "    process_batch_metrics(results, is_train, iteration)\n",
    "\n",
    "    return results\n",
    "    \n",
    "iteration = None\n",
    "for iteration in tqdm(range(1_000)):\n",
    "    process_batch(next(infinite_train_dataloader), True, iteration)\n",
    "    with torch.no_grad():\n",
    "        process_batch(next(infinite_test_dataloader), False, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2814c4ae7241b086bf51b24c4dc782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 train\n",
      "loss 0.17885324\n",
      "accuracy 0.921875\n",
      "1000 test\n",
      "loss 0.18177253\n",
      "accuracy 0.8837209302325582\n"
     ]
    }
   ],
   "source": [
    "# hacking of last layer on neural network and train only him\n",
    "for param in model.parameters():\n",
    "    model.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(X.shape[1], 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(X.shape[1], 2),\n",
    ")\n",
    "\n",
    "for iteration in tqdm(range(iteration, iteration + 100)):\n",
    "    process_batch(next(infinite_train_dataloader), True, iteration)\n",
    "    with torch.no_grad():\n",
    "        process_batch(next(infinite_test_dataloader), False, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aecc02b26364bcd9f738b0b805776b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52535107a9f4c56a9f7fa04e32b97c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9371859296482412\n",
      "Test accuracy: 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "# final metrics\n",
    "\n",
    "def predict_for_dataloader(model, dataloader):\n",
    "    Y = []\n",
    "    Y_predicted = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        result = process_batch(batch, False, None)\n",
    "        Y.append(result[\"y_numpy\"])\n",
    "        Y_predicted.append(result[\"y_predicted_numpy\"])\n",
    "    Y = np.concatenate(Y)\n",
    "    Y_predicted = np.concatenate(Y_predicted)\n",
    "    Y_predicted_class = Y_predicted.argmax(axis=1)\n",
    "    return Y, Y_predicted_class\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "Y_true_train, Y_predicted_class_train = predict_for_dataloader(model, train_dataloader)\n",
    "Y_true_test, Y_predicted_class_test = predict_for_dataloader(model, test_dataloader)\n",
    "\n",
    "print(\"Train accuracy:\", sklearn.metrics.accuracy_score(Y_true_train, Y_predicted_class_train))\n",
    "print(\"Test accuracy:\", sklearn.metrics.accuracy_score(Y_true_test, Y_predicted_class_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus for image tasks. for getting dataset for images and transform it. you coud use such code\n",
    "# from torchvision import transforms as T\n",
    "\n",
    "# transform = T.Compose([\n",
    "#     T.transforms.ToTensor(), \n",
    "#     T.transforms.Normalize([0.4, 0.4, 0.4], [0.4, 0.4, 0.4])]\n",
    "\n",
    "#     # Augmentations,\n",
    "#     # https://pytorch.org/vision/main/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "    \n",
    "# )\n",
    "\n",
    "# dataset = ImageFolder(\"your/folder\", transform=transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
