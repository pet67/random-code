{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "PYTORCH_DEVICE = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
    "print(PYTORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validators\n",
    "\n",
    "def load_text_data(filename):\n",
    "    LINE_SEPERATOR = \"##########\"\n",
    "    with open(filename) as input_file:\n",
    "        data = []\n",
    "        current_text_list = []\n",
    "        current_url = None\n",
    "        for row in tqdm(input_file):\n",
    "            if row.strip() == LINE_SEPERATOR:\n",
    "                if len(current_text_list) > 0 and current_url is not None:\n",
    "                    data.append({\n",
    "                        \"url\": current_url,\n",
    "                        \"text\": \"\".join(current_text_list).replace(\"\\xa0\", \" \"),\n",
    "                    })\n",
    "                    current_url = None\n",
    "                    current_text_list = []\n",
    "                current_url = next(input_file).strip()\n",
    "                validators.url(current_url)\n",
    "            else:\n",
    "                current_text_list.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b407efec86047f994ee1bf0d30cf319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dats size: 74232\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sklearn.model_selection\n",
    "\n",
    "data = load_text_data(\"porn_dataset.txt\")\n",
    "print(\"Dats size:\", len(data))\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "data_train, data_test = sklearn.model_selection.train_test_split(data, test_size=1_000, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "import tokenizers.models\n",
    "import tokenizers.trainers\n",
    "import tokenizers.processors\n",
    "import tokenizers.pre_tokenizers\n",
    "\n",
    "START_TOKEN = \"[START]\"\n",
    "END_TOKEN = \"[END]\"\n",
    "UNK_TOKEN = \"[UNK]\"\n",
    "\n",
    "VOCAB_SIZE = 10_000\n",
    "SPECIAL_TOKENS = [UNK_TOKEN, START_TOKEN, END_TOKEN, \".\", \",\", \"!\", \"?\", \"-\"]\n",
    "TOKENIZER_TRAIN_SIZE = 1_000\n",
    "\n",
    "tokenizer = tokenizers.Tokenizer(tokenizers.models.BPE(unk_token=UNK_TOKEN))\n",
    "tokenizer.normalizer = tokenizers.normalizers.Lowercase()\n",
    "tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.Whitespace()\n",
    "trainer = tokenizers.trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=SPECIAL_TOKENS)\n",
    "\n",
    "tokenizer_train_texts = list(map(lambda row: row[\"text\"], data_train))[:TOKENIZER_TRAIN_SIZE]\n",
    "tokenizer.train_from_iterator(tokenizer_train_texts, trainer=trainer)\n",
    "\n",
    "tokenizer.post_processor = tokenizers.processors.TemplateProcessing(\n",
    "    single=f\"{START_TOKEN} $A {END_TOKEN}\",\n",
    "    special_tokens=[\n",
    "        (START_TOKEN, tokenizer.token_to_id(START_TOKEN)),\n",
    "        (END_TOKEN, tokenizer.token_to_id(END_TOKEN)),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START]_дальше_они_с_але_ной_ста_би_льно_соз_вани_вались_два_раза_в_неделю_,_она_без_ро_по_тно_приез_жала_в_течение_трех_месяцев_и_давала_свои_ножки_на_ра_стер_за_ние_,_выполня_я_любой_ка_приз_своего_мучи_теля_-_она_поняла_,_что_проти_виться_выходит_всегда_доро_же_._если_он_хотел_с_ней_поиграть_в_его_люби_мую_игру_\"_где_тебя_по_щеко_тать_\"_или_\"_где_твои_ножки_по_лизать_\"_-_она_просто_на_зывала_место_,_больше_не_сопротивля_ясь_._приходила_теперь_она_всегда_одна_,_ей_хватило_одного_раза_._и_,_когда_,_в_последний_раз_она_приехала_,_когда_виктор_,_в_очередной_раз_выли_зал_каждый_милли_метр_ее_ступ_ней_,_он_спросил_:_-_ну_вот_и_последняя_наша_встреча_,_ты_мне_вы_пла_тила_дол_г_за_тот_телефон_._мне_очень_понрави_лись_твои_ножки_,_они_просто_беспо_доб_ны_._если_тебе_потре_бу_ются_деньги_-_ты_можешь_ко_мне_обра_титься_,_что_мне_нужно_,_ты_сама_знаешь_._тебе_такое_предложение_интересно_?_-_не_знаю_._-_алена_немного_слу_ка_вила_,_она_уже_привыкла_к_этому_бан_ди_ту_,_привыкла_к_его_игра_м_и_,_похоже_,_ей_начало_нравиться_,_когда_он_лизал_ей_ножки_._поэтому_,_ей_было_немного_гру_стно_,_что_все_закончилось_._-_может_быть_._[END]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TOKENS = None\n",
    "\n",
    "random_text = data_test[random.randint(0, len(data_test) - 1)][\"text\"]\n",
    "\n",
    "\"_\".join(tokenizer.encode(random_text).tokens[:MAX_TOKENS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1254fb8670614e07821d5ae254338ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f231efe9174e3d8ba5fdadfa22ce10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# precalculate \n",
    "\n",
    "def encode_texts_inplace(data):\n",
    "    for row in tqdm(data):\n",
    "        row[\"encoded\"] = tokenizer.encode(row[\"text\"])\n",
    "\n",
    "encode_texts_inplace(data_train)\n",
    "encode_texts_inplace(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, max_length=64, is_random_substring=True, device=PYTORCH_DEVICE):\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "        self.is_random_substring = is_random_substring\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = data[index]\n",
    "        encoded = row[\"encoded\"]\n",
    "        tokens_ids = encoded.ids\n",
    "        attention_mask = encoded.attention_mask\n",
    "        length = len(tokens_ids)\n",
    "        assert length == len(tokens_ids) == len(attention_mask)\n",
    "        \n",
    "        if self.is_random_substring and length > self.max_length:\n",
    "            random_start = random.randint(0, length - self.max_length)\n",
    "            random_end = random_start + self.max_length\n",
    "            tokens_ids = tokens_ids[random_start:random_end]\n",
    "            attention_mask = attention_mask[random_start:random_end]\n",
    "\n",
    "        return {\n",
    "            \"tokens_ids\": torch.LongTensor(tokens_ids).to(self.device),\n",
    "            \"attention_mask\": torch.LongTensor(attention_mask).to(self.device),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(original_batch):\n",
    "        batch = {\n",
    "            \"tokens_ids\": torch.nn.utils.rnn.pad_sequence(list(map(lambda x: x[\"tokens_ids\"], original_batch)), batch_first=True, padding_value=tokenizer.token_to_id(END_TOKEN)),\n",
    "            \"attention_masks\": torch.nn.utils.rnn.pad_sequence(list(map(lambda x: x[\"attention_mask\"], original_batch)), batch_first=True, padding_value=0)\n",
    "        }\n",
    "        return batch\n",
    "    \n",
    "MAX_TEXT_LENGTH = 64\n",
    "\n",
    "train_dataset = SimpleLMDataset(data_train, max_length=MAX_TEXT_LENGTH, is_random_substring=True, device=PYTORCH_DEVICE)\n",
    "test_dataset = SimpleLMDataset(data_test, max_length=MAX_TEXT_LENGTH, is_random_substring=True, device=PYTORCH_DEVICE)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=SimpleLMDataset.collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=SimpleLMDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_dataloader_wrapper(dataloader):\n",
    "    while True:\n",
    "        for batch in dataloader:\n",
    "            yield batch\n",
    "            \n",
    "infinite_train_dataloader = infinite_dataloader_wrapper(train_dataloader)\n",
    "infinite_test_dataloader = infinite_dataloader_wrapper(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLM(torch.nn.Module):\n",
    "    EMBEDDING_DIM = 64\n",
    "    \n",
    "    def __init__(self, dict_size):\n",
    "        super(SimpleLM, self).__init__()\n",
    "        self.dict_size = dict_size\n",
    "        self.embedding = nn.Embedding(dict_size, self.EMBEDDING_DIM)\n",
    "        self.lstm = nn.LSTM(self.EMBEDDING_DIM, self.EMBEDDING_DIM, batch_first=True)\n",
    "        self.final_fc = nn.Linear(self.EMBEDDING_DIM, dict_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, (_, _) = self.lstm(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.final_fc(x)\n",
    "        return F.softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0779e-04, 1.0674e-04, 8.4647e-05,  ..., 8.3036e-05,\n",
       "          1.1021e-04, 9.3027e-05],\n",
       "         [1.0465e-04, 1.1261e-04, 8.3650e-05,  ..., 8.1279e-05,\n",
       "          1.1061e-04, 1.0199e-04],\n",
       "         [1.1288e-04, 1.1751e-04, 8.3820e-05,  ..., 8.1542e-05,\n",
       "          1.1469e-04, 9.8401e-05],\n",
       "         ...,\n",
       "         [1.0618e-04, 1.1168e-04, 8.9255e-05,  ..., 8.7125e-05,\n",
       "          1.0668e-04, 9.6197e-05],\n",
       "         [1.0905e-04, 1.1439e-04, 8.9307e-05,  ..., 8.5584e-05,\n",
       "          1.0400e-04, 1.0260e-04],\n",
       "         [1.0543e-04, 1.1669e-04, 9.0656e-05,  ..., 8.1283e-05,\n",
       "          1.0115e-04, 1.0447e-04]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single run of your model\n",
    "model = SimpleLM(tokenizer.get_vocab_size())\n",
    "random_text = data_test[random.randint(0, len(data_test) - 1)][\"text\"]\n",
    "result = model(torch.LongTensor([tokenizer.encode(random_text).ids]))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLM(tokenizer.get_vocab_size()).to(PYTORCH_DEVICE)\n",
    "loss_function = torch.nn.CrossEntropyLoss().to(PYTORCH_DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645be1dc0d1d44c6971c6eb84870991a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1e1ba8312e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1_000_000_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfinite_train_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfinite_test_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-1e1ba8312e10>\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(batch, is_train, iteration)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens_predicted\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens_predicted_class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens_predicted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens_predicted_shifted\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_predicted_shifted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens_predicted_shifted_class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens_predicted_shifted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "tensorboard_writer = SummaryWriter(comment=f\"_{str(model.__class__.__name__)}\")\n",
    "\n",
    "def process_batch_metrics(results, is_train, iteration):\n",
    "    if iteration < 1000:\n",
    "        return\n",
    "    train_or_test = \"train\" if is_train else \"test\"\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(\n",
    "        results[\"tokens_ids_shifted\"].reshape(-1, 1), \n",
    "        results[\"tokens_predicted_shifted_class\"].reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    tensorboard_writer.add_scalar(f'{train_or_test}/loss', results[\"loss_numpy\"], iteration)\n",
    "    tensorboard_writer.add_scalar(f'{train_or_test}/accuracy', accuracy, iteration)\n",
    "\n",
    "\n",
    "def process_batch(batch, is_train, iteration):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    \n",
    "    tokens_ids = batch[\"tokens_ids\"]\n",
    "    attention_masks = batch[\"attention_masks\"]\n",
    "    \n",
    "    if is_train:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    tokens_predicted = model(tokens_ids)\n",
    "   \n",
    "    assert not torch.any(torch.isnan(tokens_predicted))\n",
    "    \n",
    "    tokens_predicted_shifted = tokens_predicted[:, :-1, :]\n",
    "    tokens_ids_shifted = tokens_ids[:, 1:]\n",
    "    \n",
    "    loss = loss_function(\n",
    "        tokens_predicted_shifted.reshape(-1, tokens_predicted_shifted.size(-1)),\n",
    "        tokens_ids_shifted.reshape(-1)\n",
    "    )\n",
    "    \n",
    "#     tokens_predicted_raw_selected = torch.gather(tokens_predicted_raw[:, :-1, :], dim=2, index=tokens_ids[:,1:,None])\n",
    "#     loss = -F.log_softmax(tokens_predicted_raw_selected, dim=2).mean()\n",
    "\n",
    "    if is_train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    results = {}\n",
    "    results[\"tokens_predicted\"] = tokens_predicted.cpu().detach().numpy()\n",
    "    results[\"tokens_predicted_class\"] = np.argmax(results[\"tokens_predicted\"], axis=2)\n",
    "    results[\"tokens_predicted_shifted\"] = tokens_predicted_shifted.cpu().detach().numpy()\n",
    "    results[\"tokens_predicted_shifted_class\"] = np.argmax(results[\"tokens_predicted_shifted\"], axis=2)\n",
    "\n",
    "    results[\"tokens_ids\"] = tokens_ids.cpu().detach().numpy()\n",
    "    results[\"tokens_ids_shifted\"] = tokens_ids_shifted.cpu().detach().numpy()\n",
    "\n",
    "    results[\"loss_numpy\"] = loss.cpu().detach().numpy()\n",
    "    \n",
    "    process_batch_metrics(results, is_train, iteration)\n",
    "    \n",
    "    return results\n",
    "    \n",
    "iteration = None\n",
    "for iteration in tqdm(range(1_000_000_000)):\n",
    "    process_batch(next(infinite_train_dataloader), True, iteration)\n",
    "    with torch.no_grad():\n",
    "        process_batch(next(infinite_test_dataloader), False, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
